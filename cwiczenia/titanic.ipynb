{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic data\n",
    "\n",
    "Dane mozna pobrać po utworzeniu (darmowego) konta na portalu Kaggle. \n",
    "\n",
    "[Pobierz dane](https://www.kaggle.com/c/titanic/data):\n",
    "interesują nas tylko pliki zbiorów `train.csv` i `test.csv`.\n",
    "\n",
    "Zobaczmy jak wyglądają nasze dane:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "print(\"train ma {} wierszy i {} kolumn\".format(*train.shape))\n",
    "print(\"test ma {} wierszy i {} kolumn\".format(*test.shape))\n",
    "\n",
    "print(f\"train to obiekt typu {type(train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metoda `info()` zwraca informacje o:\n",
    "- nazyach kolumn, \n",
    "- ich indeksy,\n",
    "- liczbę niepustych (`null`) elementów dla kazdej kolumny,  \n",
    "- typy danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla zbioru testowego mamy jedną kolumnę (`Survived`) mniej, dlaczego?  \n",
    "\n",
    "Ze względu, iz nie planujemy wrzucać wyników modeli na kaggle zbiór test nie jest nam potrzebny.\n",
    "\n",
    "Informacje z metody `info()` przedstawiają tylko ogólne rzeczy, zobaczmy jak zbiór train wygląda w środku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kazda kolumna reprezentuje jedną zmienną naszych danych. Identyfikatorem, bądź kluczem naszej tabeli jest `PassengerId`, która przyjmuje rózną wartość\n",
    "dla kazdego wiersza. Czy taka zmienna moze być dobra do modelowania? \n",
    "Zmienna `Survived` realizuje zmienną celu naszego zadania - pasazer przezyl (1) lub nie (0). \n",
    "`Pclass` to zmienna opisująca klasę pokładu zgodnie z biletem.\n",
    "\n",
    "### Czyszczenie danych\n",
    "\n",
    "Nasze dane zawierają zarówno dane numeryczne jak i kategoryczne. Niektóre kategorie reprezentowane są przez wartości liczbowe, a niektóre przez tekst.\n",
    "\n",
    "Na podstawie metody `info()` wiemy równiez, ze nie wszystkie kolumny mają zmienne wypełnione całkowicie. \n",
    "\n",
    "Większość algorytmów ML nie radzi sobie z brakami danych. Istnieją trzy podstawowe opcje jak mozemy sobie z tym poradzić:\n",
    "1. usunięcie wierszy w których pojawiają się jakieś braki danych.\n",
    "2. usunięcie całej kolumny gdzie występują braki danych\n",
    "3. Wypełnienie brakujących wartości (imputacja danych) zerem, wartością średnią, lub medianą."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opcja 1 - tylko 2 pasazerow nie maja Embarked - nie znamy portu docelowego - mozemy usunac te wiersze\n",
    "train = train.dropna(subset=['Embarked'])\n",
    "\n",
    "# opcja 2 - tutaj mamy tylko 204 wiersze z wartosciami w kolumnie Cabin - mozemy usunac te kolumne\n",
    "train = train.drop(\"Cabin\", axis=1)\n",
    "\n",
    "# opcja 3 - znamy wiek 714 pasazerow. Dlatego opcja 2 nie jest dobra. Opcja 1 tez nie jest dobra bo usuniemy $22\\%$ danych.\n",
    "mean = train['Age'].mean()\n",
    "train['Age'] = train['Age'].fillna(mean)\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print('Zmienna PassengerId ma {} roznych wartosci'.format(train['PassengerId'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Zmienna PassengerId ma {} roznych wartosci'.format(train['PassengerId'].nunique()))\n",
    "print('Zmienna Name ma {} roznych wartosci'.format(train['Name'].nunique()))\n",
    "print('Zmienna Ticket ma {} roznych wartosci'.format(train['Ticket'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['PassengerId', 'Name', 'Ticket'], axis=1)\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zmienne tekstowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in ['Sex','Embarked']:\n",
    "    le.fit(train[col])\n",
    "    train[col] = le.transform(train[col])\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skalowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('max wieku to {}'.format(train['Age'].max())) \n",
    "print('max zmiennej Fare to {}'.format(train['Fare'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train[['Age', 'Fare']])\n",
    "train[['Age', 'Fare']] = scaler.transform(train[['Age', 'Fare']])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test - uwaga na zwracany typ danych\n",
    "sc = MinMaxScaler()\n",
    "sc.fit(train)\n",
    "tr=sc.transform(train)\n",
    "print(type(tr),tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Podział na zbiór treningowy i testowy\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_data = train.iloc[:, 1:8]\n",
    "labels = train.iloc[:,0]\n",
    "\n",
    "tr_input, test_input, tr_labels, test_labels = train_test_split(input_data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_input.shape, test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "with open('../data/train.npy', 'wb') as f:\n",
    "    np.save(f, tr_input)\n",
    "    np.save(f, tr_labels)\n",
    "\n",
    "with open('../data/test.npy', 'wb') as f:\n",
    "    np.save(f, test_input)\n",
    "    np.save(f, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasyfikatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "# losowa funkcja klasyfikująca\n",
    "def classify(passanger):\n",
    "    return random.randint(0,1)\n",
    "\n",
    "# pomocnicza funkcja\n",
    "def run(f_classufy, x):\n",
    "    return list(map(f_classufy, x))\n",
    "\n",
    "def evaluate(predictions, actual):\n",
    "    correct = list(filter(\n",
    "        lambda item: item[0] == item[1],\n",
    "        list(zip(predictions, actual))\n",
    "    ))\n",
    "    return f\"{len(correct)} poprawnych przewidywan z {len(actual)}. Accuracy ({len(correct)/len(actual)*100:.0f}%)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(run(classify, tr_input.values), tr_labels.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kill_bill(item):\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(run(kill_bill, tr_input.values), tr_labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = run(kill_bill, tr_input.values)\n",
    "confusion_matrix(tr_labels.values, predictions)\n",
    "# TN, FP, FN, TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "print(precision_score(tr_labels.values, predictions))\n",
    "print(recall_score(tr_labels.values, predictions))\n",
    "print(f1_score(tr_labels.values, predictions))\n",
    "\n",
    "# specificity = \\sum TrueNegatives / \\sum ALLActualNegatives\n",
    "# npv = \\sum TrueNegatives / \\sum AllPredictedNegatives\n",
    "\n",
    "def specificity(matrix):\n",
    "    return matrix[0,0]/(matrix[0][0]+matrix[0][1]) if (matrix[0][0]+matrix[0][1] > 0) else 0\n",
    "\n",
    "def npv(matrix):\n",
    "    return matrix[0,0]/(matrix[0][0]+matrix[1][0]) if (matrix[0][0]+matrix[1][0] > 0) else 0\n",
    "\n",
    "cm = confusion_matrix(tr_labels.values, predictions)\n",
    "print(\"specificity\",specificity(cm))\n",
    "print(\"npv\",npv(cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Zrob obliczenia dla losowego klasyfikatora!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raport(name, run, classify, input, labels):\n",
    "    cr_predictions = run(classify, input.values)\n",
    "    cr_cm = confusion_matrix(labels.values, cr_predictions)\n",
    "    cr_prcision  = precision_score(labels.values, cr_predictions)\n",
    "    cr_recall = recall_score(labels.values, cr_predictions)\n",
    "    cr_scpecificity = specificity(cr_cm)\n",
    "    cr_npv = npv(cr_cm)\n",
    "    cr_level = 0.25*(cr_prcision + cr_recall + cr_scpecificity + cr_npv)\n",
    "    print(f\"{name} precision {cr_prcision:.2f} recall {cr_recall:.2f} specificity {cr_scpecificity:.2f} npv {cr_npv:.2f} level {cr_level:.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "losowy precision 0.37 recall 0.47 specificity 0.50 npv 0.61 level 0.49\n",
      "kill bill precision 0.00 recall 0.00 specificity 1.00 npv 0.62 level 0.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/air/Desktop/quarto_projects/intro_to_qml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "raport(\"losowy\", run, classify, tr_input, tr_labels)\n",
    "raport(\"kill bill\", run, kill_bill, tr_input, tr_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiskit\n",
    "qiskit.__qiskit_version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, execute, Aer\n",
    "from math import sqrt\n",
    "\n",
    "qc = QuantumCircuit(1)\n",
    "initial_state = [1/sqrt(2), 1/sqrt(2)]\n",
    "qc.initialize(initial_state, 0)\n",
    "qc.measure_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powyzszy obwód realizuje stan superpozycji i zwraca w losowy sposób wynik $0$ lub $1$.\n",
    "Oznacza to, ze moze byc kandydatem na klasyfikator binarny.\n",
    "\n",
    "Zdefiniujmy powyzszy obwód tak aby realizowany był jako funkcja, którą mozemy wykorzystać w naszym problemie klasyfikacji. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import execute, Aer, QuantumCircuit\n",
    "from math import sqrt \n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score \n",
    "\n",
    "def pqc_classify(backend, passenger_state):\n",
    "    qc = QuantumCircuit(1)\n",
    "    qc.initialize(passenger_state, 0)\n",
    "    qc.measure_all()\n",
    "    result = execute(qc, backend, shots=1).result()\n",
    "    counts = result.get_counts()\n",
    "    return int(list(map(lambda item: item[0], counts.items()))[0])\n",
    "\n",
    "backend = Aer.get_backend('qasm_simulator')\n",
    "initial_state = [1/sqrt(2), 1/sqrt(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random PQC precision 0.40 recall 0.53 specificity 0.50 npv 0.64 level 0.52\n"
     ]
    }
   ],
   "source": [
    "raport(\"Random PQC\", run, lambda x: pqc_classify(backend, initial_state), \n",
    "       tr_input, tr_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powyzsze kody realizują klasyfikatory, które nie zalezą od naszych danych pasazerów. \n",
    "\n",
    "1. Preprocessing - przetworznie danych wejściowych do postaci przetwarzanej przez nasz obwód kwantowy. Wykorzystamy PQC. \n",
    "Ta część jest związana z klasycznym przetworzeniem danych i utworzeniem embeddingu. \n",
    "2. PQC\n",
    "3. Postprocessing - Nasz klasyfikator powinien zwracać wartość 0 lub 1. Tutaj powinien odbywać się proces przetłumaczenia wyniku realizowanego \n",
    "przez jakiś obwód kwanotwy na binarny wynik klasyfikacji. Tutaj równiez uzyjemy PQC do klasycznego przetworzenia.\n",
    "\n",
    "Tylko druga część będzie w pełni realizowała obwód kwantowy. Łącząc wszystko razem otrzymujemy `Wariacyjny hybrydowy klasyczno-kwantowy algorytm`.\n",
    "Jest to jedno z najczęściej uzywanych podejść do modelowania danych klasycznych. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variational Classifier precision 0.41 recall 0.55 specificity 0.50 npv 0.65 level 0.53\n"
     ]
    }
   ],
   "source": [
    "# 1 preprocessing\n",
    "def pre_process(passanger):\n",
    "    quantum_state = [1/sqrt(2), 1/sqrt(2)]\n",
    "    return quantum_state\n",
    "\n",
    "# 2. pqc\n",
    "\n",
    "def pqc(beckend, quantum_state):\n",
    "    qc = QuantumCircuit(1)\n",
    "    qc.initialize(quantum_state, 0)\n",
    "    qc.measure_all()\n",
    "    result = execute(qc, backend, shots=1).result()\n",
    "    counts = result.get_counts(qc)\n",
    "    return counts\n",
    "\n",
    "# 3. postprocessing\n",
    "def post_process(counts):\n",
    "    return int(list(map(lambda item: item[0], counts.items()))[0])\n",
    "\n",
    "backend = Aer.get_backend('qasm_simulator')\n",
    "\n",
    "raport(\"Variational Classifier\", run, lambda passenger: post_process(pqc(backend, pre_process(passenger))), \n",
    "       tr_input, tr_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dane kazdego pasazera składają się z 7 zmiennych. Ze względu, iz nie chcemy (na razie) zmieniać ostatniego kroku musimy znaleźć jakąś metodę \n",
    "pozwalającą przypisać 7 zmiennym prawdopodobieństwo przezycia i śmierci. W ostatnim kroku odczytujemy po pomiarze tylko te dwie wielkości. \n",
    "\n",
    "Znalezienie prawdopodobieństwa dla 7 zmiennych nie jest prostym zadaniem (w końcu to robią nasze klasyczne modele ML). Jendak mozemy zacząć \n",
    "od bardzo statystycznego podejścia. Zakładamy, ze zmienne są od siebie niezalezne i kazda zmienna z jakąś wagą przyczynia się do wartości prawdopodobieństwa przezycia. \n",
    "$$\n",
    "P(survival) = \\sum (F \\mu_F)\n",
    "$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def waga_zmiennej(feature, weight):\n",
    "    return feature*weight\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "def get_overall_probablity(features, weights):\n",
    "    return reduce(lambda result, data: result + waga_zmiennej(*data), \n",
    "                  zip(features, weights),\n",
    "                  0\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak zbudować wektor wag? \n",
    "\n",
    "Zacznijmy od `współczynnika korelacji`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "columns = [list(map(lambda passneger: passneger[i], tr_input.values)) for i in range(0,7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = list(map(lambda col: spearmanr(col, tr_labels.values)[0], columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.33362848376406934,\n",
       " -0.5327583106581802,\n",
       " -0.03158046336028065,\n",
       " 0.0688875885695018,\n",
       " 0.12641683959850614,\n",
       " 0.3105976636091728,\n",
       " -0.16652847475942076]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zastosujmy to do pre-processingu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi, sin, cos \n",
    "\n",
    "def get_state(theta):\n",
    "    return [cos(theta/2), sin(theta/2)]\n",
    "\n",
    "def pre_process_weighted(passenger):\n",
    "    mu = get_overall_probablity(passenger, correlations)\n",
    "    # theta między 0 i pi  0 = |0> a pi = |1>\n",
    "    quantum_state = get_state((1-mu)*pi)\n",
    "    return quantum_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variational Classifier - train precision 0.28 recall 0.37 specificity 0.42 npv 0.52 level 0.39\n",
      "Variational Classifier- test precision 0.31 recall 0.38 specificity 0.48 npv 0.55 level 0.43\n"
     ]
    }
   ],
   "source": [
    "backend = Aer.get_backend('statevector_simulator')\n",
    "\n",
    "raport(\"Variational Classifier - train\", run, lambda passenger: post_process(pqc(backend, pre_process_weighted(passenger))), \n",
    "       tr_input, tr_labels)\n",
    "raport(\"Variational Classifier- test\", run, lambda passenger: post_process(pqc(backend, pre_process_weighted(passenger))), \n",
    "       test_input, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
